library(tree)
library(randomForest)
library(randomForestExplainer)
library(rpart.plot)
library(visreg)
library(rfPermute)
library(rattle)
library(PerformanceAnalytics)
library(e1071)
library(InformationValue)
library(ROCR)
library(logistf)
library(MASS)
library(pca3d)
library(doParallel)
library(kernlab)
library(klaR)
library(PCAmixdata)
library(ggplotify)
library(FactoMineR)
rpartFit1 <- train(diabetes~., data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "ROC")
rpartFit1 <- train(P_H~., data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "ROC")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "ROC")
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "ROC")
train.control <- trainControl(method = "repeatedcv",number = 10, ## 10-fold CV
repeats = 3,summaryFunction = twoClassSummary, classProbs = TRUE
)
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "ROC")
Planets_dataset_train$P_H
Planets_dataset[Planets_dataset_train,P_H]
Planets_dataset[Planets_dataset_train,]
Planets_dataset[Planets_dataset_train,]$P_H
levels(Planets_dataset[Planets_dataset_train,]$P_H)<-c("Yes","No")
View(Planets_dataset)
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
train.control <- trainControl(method = "repeatedcv",number = 10, ## 10-fold CV
repeats = 3,summaryFunction = twoClassSummary, classProbs = FALSE
)
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "ROC")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "Accuracy")
train.control <- trainControl(method = "repeatedcv",number = 10, ## 10-fold CV
repeats = 3,summaryFunction = twoClassSummary, classProbs = TRUE
)
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "Accuracy")
View(Planets_dataset_test)
Planets_dataset[Planets_dataset_train,]$P_H<- factor(Planets_dataset[Planets_dataset_train,]$P_H, levels = c(0, 1), labels = c("No", "Yes", "Three"))
Planets_dataset[Planets_dataset_train,]$P_H<- factor(Planets_dataset[Planets_dataset_train,]$P_H, levels = c(0, 1), labels = c("No", "Yes"))
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"),stringsAsFactors = FALSE)
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
View(Planets_dataset_test)
Planets_dataset[Planets_dataset_train,]$P_H<- factor(Planets_dataset[Planets_dataset_train,]$P_H, levels = c(0, 1), labels = c("No", "Yes"))
View(Planets_dataset)
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"),stringsAsFactors = FALSE)
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
levels(Planets_dataset[Planets_dataset_train,]$P_H)<- c("No", "Yes")
View(Planets_dataset_test)
View(Planets_dataset)
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"),stringsAsFactors = FALSE)
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
View(Planets_dataset)
levels(Planets_dataset[Planets_dataset_train,]$P_H)<- list(0="No",1= "Yes")
levels(Planets_dataset[Planets_dataset_train,]$P_H)<- list("0"="No","1"= "Yes")
View(Planets_dataset)
View(Planets_dataset)
levels(Planets_dataset$P_H)<- list("0"="No","1"= "Yes")
View(Planets_dataset)
levels(Planets_dataset$P_H)<- list("No"="0","Yes"= "1")
View(Planets_dataset)
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"),stringsAsFactors = FALSE)
levels(Planets_dataset$P_H)<- list("No"="0","Yes"= "1")
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
train.control <- trainControl(method = "repeatedcv",number = 10, ## 10-fold CV
repeats = 3,summaryFunction = twoClassSummary, classProbs = TRUE
)
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "Accuracy")
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"),stringsAsFactors = FALSE)
levels(Planets_dataset$P_H)<- list("No"="X0","Yes"= "X1")
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
train.control <- trainControl(method = "repeatedcv",number = 10, ## 10-fold CV
repeats = 3,summaryFunction = twoClassSummary, classProbs = TRUE
)
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "Accuracy")
#levels(Planets_dataset$P_H)<- list("No"="X0","Yes"= "X1")
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"),stringsAsFactors = FALSE)
#levels(Planets_dataset$P_H)<- list("No"="X0","Yes"= "X1")
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
levels(Planets_dataset$P_H) <- make.names(levels(factor(Planets_dataset$P_H)))
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
View(Planets_dataset_test)
train.control <- trainControl(method = "repeatedcv",number = 10, ## 10-fold CV
repeats = 3,summaryFunction = twoClassSummary, classProbs = TRUE
)
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "Accuracy")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,trControl = train.control,metric = "ROC")
rpartFit1
rpartFit1.ROC
plot(rpartFit1)
myGrid <- expand.grid(.mtry = c(1:8))
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneGrid = myGrid,trControl = train.control,metric = "ROC")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 6,
trControl = train.control,
metric = "ROC")
View(rpartFit1)
rpartFit1[["results"]]
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneLength = 10,
trControl = train.control,
metric = "ROC")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneGrid = expand.grid(cp = 0), minsplit=1
trControl = train.control,
metric = "ROC")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", tuneGrid = expand.grid(cp = 0), minsplit=1,trControl = train.control,
metric = "ROC")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2", trControl = train.control, metric = "ROC")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart2",metric = "ROC")
rpartFit1 <- train(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data=Planets_dataset[Planets_dataset_train,], method = "rpart", trControl = train.control, metric = "ROC")
plot(rpartFit1)
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5,cp=0.5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 4,cp=0.5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 1,cp=0.5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tune_dec.out=tune.rpart(method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"),stringsAsFactors = FALSE)
#levels(Planets_dataset$P_H)<- list("No"="X0","Yes"= "X1")
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
tune_dec.out=tune.rpart(method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tune_dec.out=tune.rpart(method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune.rpart(method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"),stringsAsFactors = FALSE)
#levels(Planets_dataset$P_H)<- list("No"="X0","Yes"= "X1")
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
tune_dec.out=tune.rpart(method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(method = 'class',P_H~P_P, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,],method = 'class', ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(rpart,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(rpart,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(rpart,as.factor(P_H)~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(rpart,as.factor(P_H)~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(3, 5, by = 1))))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(10,100,10))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(10,100,10))
tune_dec.out=tune(rpart2,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(10,100,10))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1), tunecontrol = tune.control(sampling = "cross",cross=10))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1), tunecontrol = tune.control(sampling = "cross",cross=10))
View(Planets_dataset)
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1), tunecontrol = tune.control(sampling = "cross",cross=10))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1), tunecontrol = tune.control(sampling = "cross",cross=10))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1))
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,])
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,])
tune_dec.out=tune(rpart,method = 'class',P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,])
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,control=rpart.control(maxdepth=6))
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 1)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 1)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 4)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 6)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 7)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 7)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 10)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
rfor.planet <-randomForest(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset, subset=Planets_dataset_train,localImp = TRUE,importance=TRUE,proximity=TRUE, mtry=2)
rfor.predict<-data.frame(predict(rfor.planet, Planets_dataset_test, type = "class"))
#explain_forest(rfor.planet)
plot(rfor.planet)
legend("top", colnames(rfor.planet$err.rate), fill=1:ncol(rfor.planet$err.rate))
varImpPlot(rfor.planet)
proximityPlot(rfor.planet)
#print(rfor.planet)
#print(importance(rfor.planet,type=2))
rfor.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(rfor.predict)<-c("Predict","Test")
caret::confusionMatrix(table(rfor.predict))
fourfoldplot(table(rfor.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Random Forest")
pred_for<-prediction(as.numeric(rfor.predict$Predict),as.numeric(rfor.predict$Test))
roc_for.perf <- performance(pred_for, measure = "tpr", x.measure = "fpr")
autoplot(roc_for.perf)+theme_bw()
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tune_dec.out=tune(rpart,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], minsplit=seq(1,10,1))
print(tune_dec.out)
plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tune_dec.out=tune(rpart,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 30, by = 1))))
tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 30, by = 1))))
print(tune_dec.out)
plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
print(tune_dec.out)
plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
print(tune_dec.out)
plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(11)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
RF_perf_out<-tuneRF(Planets_dataset[Planets_dataset_train,-c(12,1)],Planets_dataset[Planets_dataset_train,12], ntree=5000)
RF_perf_out<-data.frame(RF_perf_out)
ggplot(RF_perf_out,aes(x=mtry, y=OOBError))+geom_line(color="red",linetype="dashed")+geom_point(color="red")+theme_bw()
rfor.planet <-randomForest(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset, subset=Planets_dataset_train,localImp = TRUE,importance=TRUE,proximity=TRUE, mtry=2)
rfor.predict<-data.frame(predict(rfor.planet, Planets_dataset_test, type = "class"))
#explain_forest(rfor.planet)
plot(rfor.planet)
legend("top", colnames(rfor.planet$err.rate), fill=1:ncol(rfor.planet$err.rate))
varImpPlot(rfor.planet)
proximityPlot(rfor.planet)
#print(rfor.planet)
#print(importance(rfor.planet,type=2))
rfor.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(rfor.predict)<-c("Predict","Test")
caret::confusionMatrix(table(rfor.predict))
fourfoldplot(table(rfor.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Random Forest")
pred_for<-prediction(as.numeric(rfor.predict$Predict),as.numeric(rfor.predict$Test))
roc_for.perf <- performance(pred_for, measure = "tpr", x.measure = "fpr")
autoplot(roc_for.perf)+theme_bw()
tune_svm_full.out<-tune(svm ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M,data=Planets_dataset[Planets_dataset_train,], kernel="polynomial", ranges =list(cost=c(seq(0.01, 15, by = 0.2))))
print(tune_svm_full.out)
perf_svm<-data.frame(tune_svm_full.out[["performances"]])
ggplot(perf_svm,aes(x=cost, y=error))+geom_line(color="red",linetype="dashed")+geom_point(color="red")+theme_bw()
svm.full <- svm(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data=Planets_dataset[Planets_dataset_train,],type = 'C-classification', kernel="polynomial",cost=2)
plot(svm.full,data=Planets_dataset[Planets_dataset_train,],P_H~S_L, ylim = c(-1, 2)) #projection on P_H vs S_L in, the mistaken one are shown in the decision tree
svm.predict_full<-data.frame(predict(svm.full,Planets_dataset[Planets_dataset_train,],type = "class"))
svm.predict_full["T"]<-as.factor(Planets_dataset[Planets_dataset_train,12])
svm_fin_full<-data.frame(svm.predict_full,stringsAsFactors = TRUE)
colnames(svm_fin_full)<-c("Predict","Test")
caret::confusionMatrix(table(svm_fin_full))
fourfoldplot(table(svm_fin_full), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "SVM_FULL")
pred_svm_full<-prediction(as.numeric(svm_fin_full$Predict),as.numeric(svm_fin_full$Test))
roc_svm_full.perf <- performance(pred_svm_full, measure = "tpr", x.measure = "fpr")
phi_svm_full<-performance(pred_svm_full, "mi")
phi_svm_full@y.values
autoplot(roc_svm_full.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(12)
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(13)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
RF_perf_out<-tuneRF(Planets_dataset[Planets_dataset_train,-c(12,1)],Planets_dataset[Planets_dataset_train,12], ntree=5000)
RF_perf_out<-data.frame(RF_perf_out)
ggplot(RF_perf_out,aes(x=mtry, y=OOBError))+geom_line(color="red",linetype="dashed")+geom_point(color="red")+theme_bw()
rfor.planet <-randomForest(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset, subset=Planets_dataset_train,localImp = TRUE,importance=TRUE,proximity=TRUE, mtry=2)
rfor.predict<-data.frame(predict(rfor.planet, Planets_dataset_test, type = "class"))
tune_svm_full.out<-tune(svm ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M,data=Planets_dataset[Planets_dataset_train,], kernel="polynomial", ranges =list(cost=c(seq(0.01, 15, by = 0.2))))
print(tune_svm_full.out)
perf_svm<-data.frame(tune_svm_full.out[["performances"]])
ggplot(perf_svm,aes(x=cost, y=error))+geom_line(color="red",linetype="dashed")+geom_point(color="red")+theme_bw()
