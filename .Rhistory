Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(11)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
RF_perf_out<-tuneRF(Planets_dataset[Planets_dataset_train,-c(12,1)],Planets_dataset[Planets_dataset_train,12], ntree=5000)
RF_perf_out<-data.frame(RF_perf_out)
ggplot(RF_perf_out,aes(x=mtry, y=OOBError))+geom_line(color="red",linetype="dashed")+geom_point(color="red")+theme_bw()
rfor.planet <-randomForest(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset, subset=Planets_dataset_train,localImp = TRUE,importance=TRUE,proximity=TRUE, mtry=2)
rfor.predict<-data.frame(predict(rfor.planet, Planets_dataset_test, type = "class"))
#explain_forest(rfor.planet)
plot(rfor.planet)
legend("top", colnames(rfor.planet$err.rate), fill=1:ncol(rfor.planet$err.rate))
varImpPlot(rfor.planet)
proximityPlot(rfor.planet)
#print(rfor.planet)
#print(importance(rfor.planet,type=2))
rfor.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(rfor.predict)<-c("Predict","Test")
caret::confusionMatrix(table(rfor.predict))
fourfoldplot(table(rfor.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Random Forest")
pred_for<-prediction(as.numeric(rfor.predict$Predict),as.numeric(rfor.predict$Test))
roc_for.perf <- performance(pred_for, measure = "tpr", x.measure = "fpr")
autoplot(roc_for.perf)+theme_bw()
tune_svm_full.out<-tune(svm ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M,data=Planets_dataset[Planets_dataset_train,], kernel="polynomial", ranges =list(cost=c(seq(0.01, 15, by = 0.2))))
print(tune_svm_full.out)
perf_svm<-data.frame(tune_svm_full.out[["performances"]])
ggplot(perf_svm,aes(x=cost, y=error))+geom_line(color="red",linetype="dashed")+geom_point(color="red")+theme_bw()
svm.full <- svm(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M, data=Planets_dataset[Planets_dataset_train,],type = 'C-classification', kernel="polynomial",cost=2)
plot(svm.full,data=Planets_dataset[Planets_dataset_train,],P_H~S_L, ylim = c(-1, 2)) #projection on P_H vs S_L in, the mistaken one are shown in the decision tree
svm.predict_full<-data.frame(predict(svm.full,Planets_dataset[Planets_dataset_train,],type = "class"))
svm.predict_full["T"]<-as.factor(Planets_dataset[Planets_dataset_train,12])
svm_fin_full<-data.frame(svm.predict_full,stringsAsFactors = TRUE)
colnames(svm_fin_full)<-c("Predict","Test")
caret::confusionMatrix(table(svm_fin_full))
fourfoldplot(table(svm_fin_full), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "SVM_FULL")
pred_svm_full<-prediction(as.numeric(svm_fin_full$Predict),as.numeric(svm_fin_full$Test))
roc_svm_full.perf <- performance(pred_svm_full, measure = "tpr", x.measure = "fpr")
phi_svm_full<-performance(pred_svm_full, "mi")
phi_svm_full@y.values
autoplot(roc_svm_full.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(12)
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(13)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
RF_perf_out<-tuneRF(Planets_dataset[Planets_dataset_train,-c(12,1)],Planets_dataset[Planets_dataset_train,12], ntree=5000)
RF_perf_out<-data.frame(RF_perf_out)
ggplot(RF_perf_out,aes(x=mtry, y=OOBError))+geom_line(color="red",linetype="dashed")+geom_point(color="red")+theme_bw()
rfor.planet <-randomForest(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset, subset=Planets_dataset_train,localImp = TRUE,importance=TRUE,proximity=TRUE, mtry=2)
rfor.predict<-data.frame(predict(rfor.planet, Planets_dataset_test, type = "class"))
tune_svm_full.out<-tune(svm ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M,data=Planets_dataset[Planets_dataset_train,], kernel="polynomial", ranges =list(cost=c(seq(0.01, 15, by = 0.2))))
print(tune_svm_full.out)
perf_svm<-data.frame(tune_svm_full.out[["performances"]])
ggplot(perf_svm,aes(x=cost, y=error))+geom_line(color="red",linetype="dashed")+geom_point(color="red")+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(1)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
library(readxl)
library(ISLR)
library(readxl)
library(devtools)
library(ggfortify)
library(ggrepel)
library(ggplot2)
library(corrplot)
library(factoextra)
library(dendextend)
library(mdendro)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)
library(randomForestExplainer)
library(rpart.plot)
library(visreg)
library(rfPermute)
library(rattle)
library(PerformanceAnalytics)
library(e1071)
library(InformationValue)
library(ROCR)
library(logistf)
library(MASS)
library(pca3d)
library(doParallel)
library(kernlab)
library(klaR)
library(PCAmixdata)
library(ggplotify)
library(FactoMineR)
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(1)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(2)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(3)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(4)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(5)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(6)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(7)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(8)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(9)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
Planets_dataset <- data.frame(read_excel("phl_exoplanet_catalog_FINAL.xlsx"))
Planets_dataset[,12]<-as.factor(Planets_dataset[,12])
Planets_dataset[,15]<-as.factor(Planets_dataset[,15])
set.seed(10)
#########Splitting training vs test set
Planets_dataset_train<- sample(500,350)
Planets_dataset_test<-Planets_dataset[-Planets_dataset_train,]
#########Plotting the correlation chart
#chart.Correlation(Planets_dataset[,2:15], histogram=FALSE)
palette = colorRampPalette(c("green", "blue", "red")) (20)
heatmap(x = cor(Planets_dataset[,2:15]), col = palette, symm = TRUE, margins = c(10, 10),main = 'Planet Features',dist(Planets_dataset[,2:15],method = 'euclidean'))
#########Decision Tree
#tune_dec.out=tune(rpart ,P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T, data= Planets_dataset[Planets_dataset_train,], ranges =list(minsplit=c(seq(1, 50, by = 1))))
#print(tune_dec.out)
#plot(tune_dec.out,type="contour",swapxy = TRUE,mar = c(2, 1, 1, 2))
tree.planet <- rpart(P_H~P_P+S_T+P_D+P_PN+P_A+P_D_E+P_F+P_T_E+S_R_E+S_L+P_R+P_M+S_S_T,data=Planets_dataset,method="class", subset=Planets_dataset_train,minsplit = 5)
fancyRpartPlot(tree.planet,sub = "Planets Habitability", palettes = "OrRd")
tree.predict<-data.frame(predict(tree.planet, Planets_dataset_test, type = "class"))
rpart.plot(tree.planet,box.palette=c("red", "green"),digits=4,extra=106)
tree.predict["Test"]<-as.factor(Planets_dataset_test[,12])
colnames(tree.predict)<-c("Predict","Test")
caret::confusionMatrix(table(tree.predict))
fourfoldplot(table(tree.predict), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
pred_dec<-prediction(as.numeric(tree.predict$Predict),as.numeric(tree.predict$Test))
roc_dec.perf <- performance(pred_dec, measure = "tpr", x.measure = "fpr")
autoplot(roc_dec.perf)+theme_bw()
dataframe(conf_matrix)
data.frame(conf_matrix)
View(pred_dec)
View(tree.predict)
conf_matrix <- data.frame (first_column  = c(134, 1),second_column = c(2,13))
)
conf_matrix <- data.frame (first_column  = c(134, 1),second_column = c(2,13))
View(conf_matrix)
table(conf_matrix <- data.frame (first_column  = c(134, 1),second_column = c(2,13)))
conf_matrix <- data.frame (first_column  = c(134, 1),second_column = c(2,13))
colnames(conf_matrix)<-c("Predict","Test")
View(conf_matrix)
colnames(conf_matrix)<-c("P","T")
rownames(conf_matrix)<-c("P","T")
View(conf_matrix)
colnames(conf_matrix)<-c("0","1")
rownames(conf_matrix)<-c("0","1")
View(conf_matrix)
table(conf_matrix)
caret::confusionMatrix(conf_matrix)
lvs <- c("0", "1")
conf_matrix <- factor(c(rep(lvs, times = c(13, 2)),rep(lvs, times = c(1, 134))),levels = rev(lvs))
conf_matrix
table(conf_matrix )
caret::confusionMatrix(table(conf_matrix ))
caret::confusionMatrix(table(conf_matrix ))
truth <- factor(rep(lvs, times = c(86, 258)),
levels = rev(lvs))
caret::confusionMatrix(table(conf_matrix,truth ))
library(readxl)
library(ISLR)
library(readxl)
library(devtools)
library(ggfortify)
library(ggrepel)
library(ggplot2)
library(corrplot)
library(factoextra)
library(dendextend)
library(mdendro)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)
library(randomForestExplainer)
library(rpart.plot)
library(visreg)
library(rfPermute)
library(rattle)
library(PerformanceAnalytics)
library(e1071)
library(InformationValue)
library(ROCR)
library(logistf)
library(MASS)
library(pca3d)
library(doParallel)
library(kernlab)
library(klaR)
library(PCAmixdata)
library(ggplotify)
library(FactoMineR)
library(readxl)
Conf_matrix <- read_excel("Conf_matrix.xlsx")
View(Conf_matrix)
data<-data.fame(Conf_matrix)
data<-data.frame(Conf_matrix)
View(data)
data<-as.factor(data)
table(data)
Conf_matrix <- read_excel("Conf_matrix.xlsx")
Conf_matrix <- as.factor(Conf_matrix)
Conf_matrix<-data.frame(Conf_matrix)
View(Conf_matrix)
Conf_matrix <- read_excel("Conf_matrix.xlsx")
table(Conf_matrix)
caret::confusionMatrix(table(Conf_matrix))
fourfoldplot(table(Conf_matrix), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree")
fourfoldplot(table(Conf_matrix), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision Tree FINAL CV")
save(Conf_matrix, file = "Decision Tree FINAL CV")
fourfoldplot(table(Conf_matrix), color = c("red","darkgreen"),conf.level = 0, margin = 1, main = "Decision_Tree_FINAL_CV.rda")
